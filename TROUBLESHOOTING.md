# Guide de R√©solution des Probl√®mes - Collecte de News

## ‚ö†Ô∏è Erreurs Fr√©quentes et Solutions

### 1. Erreur: "Expecting value: line 1 column 1 (char 0)"

**Sympt√¥me** :
```
ERROR | Erreur GDELT: Expecting value: line 1 column 1 (char 0)
```

**Cause** :
- GDELT retourne une r√©ponse vide (pas de donn√©es pour cette requ√™te)
- Les keywords sont trop sp√©cifiques ou ne matchent aucune news
- P√©riode de collecte trop courte

**Solutions** :

1. **Augmenter la p√©riode de collecte**
   ```python
   # Au lieu de 5 jours
   start_date="2024-01-15"
   end_date="2024-01-20"

   # Utiliser une p√©riode plus longue
   start_date="2023-01-01"
   end_date="2024-12-31"
   ```

2. **Simplifier les keywords** dans `config/news_strategy.yaml`
   ```yaml
   # Trop sp√©cifique (peut √©chouer)
   keywords:
     - "European Central Bank monetary policy decision"

   # Mieux (plus de chances de match)
   keywords:
     - "ECB"
     - "monetary policy"
     - "interest rate"
   ```

3. **Augmenter max_records**
   ```python
   collector.collect_and_map(
       max_records_per_query=250  # Au lieu de 50
   )
   ```

4. **C'est normal !**
   - Certaines requ√™tes ne retournent pas de r√©sultats
   - Le syst√®me continue automatiquement
   - Tant que QUELQUES requ√™tes r√©ussissent, c'est OK

---

### 2. Erreur: "429 Client Error: Too Many Requests"

**Sympt√¥me** :
```
ERROR | Erreur GDELT: 429 Client Error: Too Many Requests
```

**Cause** :
- GDELT limite le nombre de requ√™tes par minute
- Trop de requ√™tes en peu de temps

**Solutions** :

1. **Augmenter le d√©lai entre requ√™tes**
   ```python
   collector.collect_and_map(
       delay=3.0  # Au lieu de 2.0 secondes
   )
   ```

2. **R√©duire le nombre de requ√™tes**
   - √âditer `config/news_strategy.yaml`
   - Supprimer les √©v√©nements moins importants
   - Regrouper les keywords similaires

3. **Collecte par lots**
   ```python
   # Collecter macro puis attendre
   macro_df = collector.fetch_macro_news(...)
   time.sleep(60)  # Attendre 1 minute

   # Puis collecter sectoriel
   sector_df = collector.fetch_sector_news(...)
   ```

4. **Utiliser d'autres sources**
   - NewsAPI (payant mais plus fiable)
   - Finnhub (limit√© mais stable)
   - RSS feeds directs

---

### 3. Peu de News Collect√©es

**Sympt√¥me** :
```
16 news uniques collect√©es (au lieu de 200+ attendues)
```

**Causes** :
- P√©riode de collecte trop courte
- Keywords trop sp√©cifiques
- Beaucoup de requ√™tes √©chouent

**Solutions** :

1. **P√©riode plus longue**
   ```python
   # Test court (16 news)
   start_date="2024-01-15"
   end_date="2024-01-20"  # 5 jours

   # Collecte r√©elle (beaucoup plus)
   start_date="2023-01-01"
   end_date="2024-12-31"  # 2 ans
   ```

2. **Keywords plus g√©n√©riques**
   ```yaml
   # Dans config/news_strategy.yaml
   monetary_policy:
     keywords:
       - "Fed"  # Court et fr√©quent
       - "ECB"
       - "interest"
       - "inflation"
   ```

3. **R√©duire min_relevance_score**
   ```python
   collector.collect_and_map(
       min_relevance_score=3.0  # Au lieu de 5.0
   )
   ```

---

## üéØ Configuration Optimale

### Pour Tests Rapides (comme demo)
```python
collector.collect_and_map(
    start_date="2024-01-01",
    end_date="2024-01-31",  # 1 mois
    min_relevance_score=5.0,
    max_records_per_query=50,  # R√©duit
    delay=2.0
)
```

### Pour Collecte R√©elle
```python
collector.collect_and_map(
    start_date="2023-01-01",
    end_date="2024-12-31",  # 2 ans
    min_relevance_score=4.0,  # Plus permissif
    max_records_per_query=250,  # Maximum
    delay=3.0  # Plus de d√©lai
)
```

### Pour Production (tr√®s stable)
```python
# Collecter par morceaux de 1 mois
import pandas as pd
from datetime import datetime, timedelta

all_news = []
start = datetime(2023, 1, 1)
end = datetime(2024, 12, 31)

current = start
while current < end:
    next_month = current + timedelta(days=30)

    print(f"Collecte: {current.date()} ‚Üí {next_month.date()}")

    news = collector.collect_and_map(
        start_date=current.strftime("%Y-%m-%d"),
        end_date=next_month.strftime("%Y-%m-%d"),
        min_relevance_score=4.0,
        max_records_per_query=250,
        delay=3.0
    )

    if not news.empty:
        all_news.append(news)

    # Pause entre chaque mois
    time.sleep(120)  # 2 minutes

    current = next_month

# Combiner tout
final_df = pd.concat(all_news, ignore_index=True)
```

---

## üìä Interpr√©ter les R√©sultats

### R√©sultats Normaux
```
Total articles collect√©s: 200
  - √âv√©nements macro: 150
  - √âv√©nements sectoriels: 50
Doublons supprim√©s: 50
Articles uniques finaux: 150
```

‚úÖ C'est OK ! M√™me avec des erreurs, on a des r√©sultats.

### R√©sultats Pr√©occupants
```
Total articles collect√©s: 5
Doublons supprim√©s: 0
Articles uniques finaux: 5
```

‚ùå Tr√®s peu de donn√©es. Actions √† prendre :
1. Augmenter la p√©riode
2. Simplifier les keywords
3. R√©duire min_relevance_score
4. V√©rifier la connexion Internet

---

## üîß Diagnostics

### V√©rifier si GDELT fonctionne
```python
import requests

# Test manuel
response = requests.get(
    "https://api.gdeltproject.org/api/v2/doc/doc",
    params={
        'query': 'inflation',
        'mode': 'artlist',
        'maxrecords': 10,
        'format': 'json',
        'startdatetime': '20240101000000',
        'enddatetime': '20240131000000'
    }
)

print(f"Status: {response.status_code}")
print(f"Contenu: {response.text[:200]}")
```

### V√©rifier les keywords
```python
from src.collectors.news_impact_mapper import NewsImpactMapper

mapper = NewsImpactMapper()

# Combien de requ√™tes ?
macro = mapper.get_macro_event_queries()
sector = mapper.get_sector_event_queries()

print(f"Requ√™tes macro: {len(macro)}")
print(f"Requ√™tes sectorielles: {len(sector)}")
print(f"Total: {len(macro) + len(sector)}")

# Si > 50, c'est beaucoup pour GDELT
```

---

## üí° Recommandations

### Pour votre projet

1. **Phase de test** (maintenant)
   - P√©riode courte (1-3 mois)
   - V√©rifier que √ßa marche
   - Ajuster keywords et scores

2. **Collecte historique** (ensuite)
   - 2-3 ans de donn√©es
   - Par morceaux de 1 mois
   - Sauvegarder apr√®s chaque mois

3. **Production** (long terme)
   - Collecte quotidienne automatique
   - Monitoring des erreurs
   - Alerte si trop d'√©checs

### Keywords √† Privil√©gier

**‚ùå √âviter** (trop sp√©cifiques) :
```yaml
- "European Central Bank interest rate decision announcement"
- "Federal Reserve quantitative easing policy meeting"
```

**‚úÖ Pr√©f√©rer** (g√©n√©riques) :
```yaml
- "ECB"
- "Fed"
- "interest rate"
- "inflation"
```

---

## üìù Notes Importantes

1. **Les erreurs sont normales** : GDELT est gratuit et instable. 30-50% d'erreurs est acceptable.

2. **Qualit√© > Quantit√©** : 50 news pertinentes valent mieux que 500 news non pertinentes.

3. **Diversifier les sources** : Ne pas d√©pendre uniquement de GDELT. Envisager :
   - NewsAPI (payant)
   - Finnhub (limit√© gratuit)
   - RSS feeds directs
   - Web scraping de sites sp√©cifiques

4. **Patience** : Une collecte sur 2 ans peut prendre 2-3 heures √† cause des d√©lais.

---

**Derni√®re mise √† jour** : 2026-01-14
