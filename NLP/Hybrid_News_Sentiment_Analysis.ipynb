{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b3bd8a",
   "metadata": {},
   "source": [
    "# Analyse de Sentiment des News Hybrides\n",
    "\n",
    "Ce notebook r√©cup√®re les news collect√©es via le syst√®me hybride et applique l'analyse de sentiment avec le mod√®le FinBERT fine-tun√©.\n",
    "\n",
    "**Workflow:**\n",
    "1. Chargement des news depuis `hybrid_news_mapped.csv`\n",
    "2. Initialisation du mod√®le FinBERT de sentiment\n",
    "3. Analyse de sentiment pour chaque article\n",
    "4. Enrichissement des donn√©es avec les scores de sentiment\n",
    "5. Export des r√©sultats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e37f20",
   "metadata": {},
   "source": [
    "## 1. Import des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7be64211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Documents\\ECE\\2025\\PFE\\FinsightAI\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Biblioth√®ques import√©es avec succ√®s\n",
      "‚úì PyTorch version: 2.5.1+cu121\n",
      "‚úì Device disponible: GPU\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úì Biblioth√®ques import√©es avec succ√®s\")\n",
    "print(f\"‚úì PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úì Device disponible: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290d0286",
   "metadata": {},
   "source": [
    "## 2. Chargement des donn√©es de news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be7aa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Chargement des news depuis: ..\\Pipeline_Recup_Donnees\\data\\raw\\news\\hybrid_news_mapped.csv\n",
      "\n",
      "‚úì 4280 lignes charg√©es\n",
      "‚úì Colonnes: ['date', 'title', 'url', 'source', 'language', 'event_type', 'event_category', 'base_impact_score', 'affects', 'asset', 'relevance_score', 'matched_events']\n",
      "\n",
      "üìä Dimensions: (4280, 12)\n",
      "üì∞ News uniques: 377\n",
      "üìà Actifs concern√©s: 18\n",
      "\n",
      "üìã Aper√ßu des donn√©es:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>source</th>\n",
       "      <th>language</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_category</th>\n",
       "      <th>base_impact_score</th>\n",
       "      <th>affects</th>\n",
       "      <th>asset</th>\n",
       "      <th>relevance_score</th>\n",
       "      <th>matched_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-09 06:15:00</td>\n",
       "      <td>Mercosur - kauppasopimus ratkaisevassa nestyks...</td>\n",
       "      <td>https://yle.fi/a/74-20203286</td>\n",
       "      <td>yle.fi</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>trade_policy</td>\n",
       "      <td>macro</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>19.2</td>\n",
       "      <td>technology, automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-09 06:15:00</td>\n",
       "      <td>Mercosur - kauppasopimus ratkaisevassa nestyks...</td>\n",
       "      <td>https://yle.fi/a/74-20203286</td>\n",
       "      <td>yle.fi</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>trade_policy</td>\n",
       "      <td>macro</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPLE</td>\n",
       "      <td>9.6</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-09 06:15:00</td>\n",
       "      <td>Mercosur - kauppasopimus ratkaisevassa nestyks...</td>\n",
       "      <td>https://yle.fi/a/74-20203286</td>\n",
       "      <td>yle.fi</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>trade_policy</td>\n",
       "      <td>macro</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AMAZON</td>\n",
       "      <td>9.6</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-09 06:15:00</td>\n",
       "      <td>Mercosur - kauppasopimus ratkaisevassa nestyks...</td>\n",
       "      <td>https://yle.fi/a/74-20203286</td>\n",
       "      <td>yle.fi</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>trade_policy</td>\n",
       "      <td>macro</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STELLANTIS</td>\n",
       "      <td>9.6</td>\n",
       "      <td>automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-09 06:15:00</td>\n",
       "      <td>Mercosur - kauppasopimus ratkaisevassa nestyks...</td>\n",
       "      <td>https://yle.fi/a/74-20203286</td>\n",
       "      <td>yle.fi</td>\n",
       "      <td>Finnish</td>\n",
       "      <td>trade_policy</td>\n",
       "      <td>macro</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CASIC</td>\n",
       "      <td>9.6</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              title  \\\n",
       "0  2026-01-09 06:15:00  Mercosur - kauppasopimus ratkaisevassa nestyks...   \n",
       "1  2026-01-09 06:15:00  Mercosur - kauppasopimus ratkaisevassa nestyks...   \n",
       "2  2026-01-09 06:15:00  Mercosur - kauppasopimus ratkaisevassa nestyks...   \n",
       "3  2026-01-09 06:15:00  Mercosur - kauppasopimus ratkaisevassa nestyks...   \n",
       "4  2026-01-09 06:15:00  Mercosur - kauppasopimus ratkaisevassa nestyks...   \n",
       "\n",
       "                            url  source language    event_type event_category  \\\n",
       "0  https://yle.fi/a/74-20203286  yle.fi  Finnish  trade_policy          macro   \n",
       "1  https://yle.fi/a/74-20203286  yle.fi  Finnish  trade_policy          macro   \n",
       "2  https://yle.fi/a/74-20203286  yle.fi  Finnish  trade_policy          macro   \n",
       "3  https://yle.fi/a/74-20203286  yle.fi  Finnish  trade_policy          macro   \n",
       "4  https://yle.fi/a/74-20203286  yle.fi  Finnish  trade_policy          macro   \n",
       "\n",
       "   base_impact_score affects       asset  relevance_score  \\\n",
       "0                  8     NaN       TESLA             19.2   \n",
       "1                  8     NaN       APPLE              9.6   \n",
       "2                  8     NaN      AMAZON              9.6   \n",
       "3                  8     NaN  STELLANTIS              9.6   \n",
       "4                  8     NaN       CASIC              9.6   \n",
       "\n",
       "           matched_events  \n",
       "0  technology, automotive  \n",
       "1              technology  \n",
       "2              technology  \n",
       "3              automotive  \n",
       "4              technology  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chemins des fichiers\n",
    "NEWS_CSV_PATH = Path(\"../Pipeline_Recup_Donnees/data/raw/news/hybrid_news_mapped.csv\")\n",
    "\n",
    "# Chargement du fichier CSV\n",
    "print(f\"üìÇ Chargement des news depuis: {NEWS_CSV_PATH}\")\n",
    "df_news = pd.read_csv(NEWS_CSV_PATH)\n",
    "\n",
    "# Affichage des informations de base\n",
    "print(f\"\\n‚úì {len(df_news)} lignes charg√©es\")\n",
    "print(f\"‚úì Colonnes: {list(df_news.columns)}\")\n",
    "print(f\"\\nüìä Dimensions: {df_news.shape}\")\n",
    "print(f\"üì∞ News uniques: {df_news['url'].nunique()}\")\n",
    "print(f\"üìà Actifs concern√©s: {df_news['asset'].nunique()}\")\n",
    "\n",
    "# Affichage d'un √©chantillon\n",
    "print(\"\\nüìã Aper√ßu des donn√©es:\")\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca274620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç V√©rification des valeurs manquantes:\n",
      "title         0\n",
      "url           0\n",
      "asset         0\n",
      "event_type    0\n",
      "dtype: int64\n",
      "\n",
      "üì∞ Avant d√©duplication: 4280 entr√©es\n",
      "üì∞ Apr√®s d√©duplication: 377 news uniques\n",
      "\n",
      "üìå Exemples de titres de news:\n",
      "  1. Mercosur - kauppasopimus ratkaisevassa nestyksess√§ 25 vuoden neuvottelujen j√§lke...\n",
      "  2. Iran in 2026 : Isolated in a Turbulent Ocean...\n",
      "  3. R√ºstung im W√ºrgegriff : Warum Lockheed und Boeing ohne Antimon am Boden bleiben ...\n",
      "  4. Tariff shock could weigh on jobs while easing inflation , Fed Research suggests...\n",
      "  5. Aktien von Advantest , Renesas und Softbank brechen ein : Politischer Schock aus...\n"
     ]
    }
   ],
   "source": [
    "# V√©rification des donn√©es manquantes dans les colonnes cl√©s\n",
    "print(\"üîç V√©rification des valeurs manquantes:\")\n",
    "missing_data = df_news[['title', 'url', 'asset', 'event_type']].isnull().sum()\n",
    "print(missing_data)\n",
    "\n",
    "# D√©dupliquer par URL pour avoir des news uniques\n",
    "print(f\"\\nüì∞ Avant d√©duplication: {len(df_news)} entr√©es\")\n",
    "df_news_unique = df_news.drop_duplicates(subset=['url']).copy()\n",
    "print(f\"üì∞ Apr√®s d√©duplication: {len(df_news_unique)} news uniques\")\n",
    "\n",
    "# Afficher quelques exemples de titres\n",
    "print(\"\\nüìå Exemples de titres de news:\")\n",
    "for idx, title in enumerate(df_news_unique['title'].head(5), 1):\n",
    "    print(f\"  {idx}. {title[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43861ab",
   "metadata": {},
   "source": [
    "## 3. Initialisation du mod√®le FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f430c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Device: cuda\n",
      "\n",
      "üì• Chargement du mod√®le depuis: ./news_finbert_sentiment_model\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Error no file named model.safetensors found in directory ./news_finbert_sentiment_model.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Chargement du mod√®le et du tokenizer\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müì• Chargement du mod√®le depuis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m model.to(device)\n\u001b[32m     16\u001b[39m model.eval()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\ECE\\2025\\PFE\\FinsightAI\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\ECE\\2025\\PFE\\FinsightAI\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\ECE\\2025\\PFE\\FinsightAI\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4900\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4891\u001b[39m     gguf_file\n\u001b[32m   4892\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4893\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4894\u001b[39m ):\n\u001b[32m   4895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4896\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4897\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4898\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4900\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4902\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4920\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4921\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\ECE\\2025\\PFE\\FinsightAI\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:984\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m    978\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    979\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m found in directory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    980\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but there is a file for Flax weights. Use `from_flax=True`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    981\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m to load this model from those weights.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    982\u001b[39m     )\n\u001b[32m    983\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m use_safetensors:\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    985\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m found in directory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    986\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    987\u001b[39m     )\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError no file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_add_variant(SAFE_WEIGHTS_NAME,\u001b[38;5;250m \u001b[39mvariant)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m.index\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFLAX_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m found in directory\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[31mOSError\u001b[39m: Error no file named model.safetensors found in directory ./news_finbert_sentiment_model."
     ]
    }
   ],
   "source": [
    "# Configuration du device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "\n",
    "# Chemin du mod√®le\n",
    "MODEL_PATH = \"./news_finbert_sentiment_model\"\n",
    "\n",
    "# Chargement du mod√®le et du tokenizer\n",
    "print(f\"\\nüì• Chargement du mod√®le depuis: {MODEL_PATH}\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=2,\n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "print(\"‚úì Mod√®le FinBERT charg√© et pr√™t\")\n",
    "print(f\"‚úì Configuration: {model.config.num_labels} labels (0=Negative, 1=Positive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76839297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test rapide du mod√®le\n",
    "test_text = \"Stock market reaches new all-time high as economic growth surges\"\n",
    "print(f\"\\nüß™ Test du mod√®le avec: '{test_text}'\")\n",
    "\n",
    "# Tokenization de test\n",
    "test_encoding = tokenizer(\n",
    "    test_text,\n",
    "    add_special_tokens=True,\n",
    "    max_length=512,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Pr√©diction de test\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(\n",
    "        input_ids=test_encoding['input_ids'].to(device),\n",
    "        attention_mask=test_encoding['attention_mask'].to(device)\n",
    "    )\n",
    "    test_probs = F.softmax(test_outputs.logits, dim=1)[0]\n",
    "    test_prediction = torch.argmax(test_outputs.logits, dim=1).item()\n",
    "\n",
    "print(f\"‚úì Pr√©diction: {'Positive' if test_prediction == 1 else 'Negative'}\")\n",
    "print(f\"‚úì Prob Negative: {test_probs[0].item():.2%}\")\n",
    "print(f\"‚úì Prob Positive: {test_probs[1].item():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c952e1f",
   "metadata": {},
   "source": [
    "## 4. Fonction d'analyse de sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87849ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text, model, tokenizer, device, max_length=512):\n",
    "    \"\"\"\n",
    "    Analyse le sentiment d'un texte avec le mod√®le FinBERT\n",
    "    \n",
    "    Args:\n",
    "        text: Texte √† analyser (titre de la news)\n",
    "        model: Mod√®le FinBERT\n",
    "        tokenizer: Tokenizer\n",
    "        device: CPU ou GPU\n",
    "        max_length: Longueur maximale (512 pour FinBERT)\n",
    "    \n",
    "    Returns:\n",
    "        dict avec sentiment, confiance, et probabilit√©s\n",
    "    \"\"\"\n",
    "    \n",
    "    # Gestion des textes vides ou null\n",
    "    if not text or pd.isna(text) or len(str(text).strip()) == 0:\n",
    "        return {\n",
    "            'sentiment': 'Unknown',\n",
    "            'confidence': 0.0,\n",
    "            'prob_negative': 0.5,\n",
    "            'prob_positive': 0.5\n",
    "        }\n",
    "    \n",
    "    # Tokenization\n",
    "    encoding = tokenizer(\n",
    "        str(text),\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Pr√©diction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=1)[0]\n",
    "        \n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        confidence = probabilities[prediction].item()\n",
    "    \n",
    "    # Labels: 0=Negative, 1=Positive\n",
    "    sentiment_label = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment_label,\n",
    "        'confidence': confidence,\n",
    "        'prob_negative': probabilities[0].item(),\n",
    "        'prob_positive': probabilities[1].item()\n",
    "    }\n",
    "\n",
    "print(\"‚úì Fonction analyze_sentiment d√©finie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65016ec4",
   "metadata": {},
   "source": [
    "## 5. Analyse de sentiment sur toutes les news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fde593",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ü§ñ D√âBUT DE L'ANALYSE DE SENTIMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Pr√©parer les listes pour stocker les r√©sultats\n",
    "sentiments = []\n",
    "confidences = []\n",
    "prob_negatives = []\n",
    "prob_positives = []\n",
    "\n",
    "total_news = len(df_news_unique)\n",
    "print(f\"\\nüì∞ Analyse de {total_news} news uniques...\\n\")\n",
    "\n",
    "# Analyser chaque news\n",
    "for idx, row in df_news_unique.iterrows():\n",
    "    # Utiliser le titre pour l'analyse\n",
    "    title = row['title']\n",
    "    \n",
    "    # Analyser le sentiment\n",
    "    result = analyze_sentiment(title, model, tokenizer, device)\n",
    "    \n",
    "    # Stocker les r√©sultats\n",
    "    sentiments.append(result['sentiment'])\n",
    "    confidences.append(result['confidence'])\n",
    "    prob_negatives.append(result['prob_negative'])\n",
    "    prob_positives.append(result['prob_positive'])\n",
    "    \n",
    "    # Afficher la progression tous les 10%\n",
    "    progress = (len(sentiments) / total_news) * 100\n",
    "    if len(sentiments) % max(1, total_news // 10) == 0:\n",
    "        print(f\"   ‚è≥ Progression: {progress:.0f}% ({len(sentiments)}/{total_news})\")\n",
    "\n",
    "# Ajouter les colonnes au DataFrame\n",
    "df_news_unique['sentiment'] = sentiments\n",
    "df_news_unique['confidence'] = confidences\n",
    "df_news_unique['prob_negative'] = prob_negatives\n",
    "df_news_unique['prob_positive'] = prob_positives\n",
    "\n",
    "print(f\"\\n‚úì Analyse termin√©e pour {total_news} news\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5e58ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher un aper√ßu des r√©sultats\n",
    "print(\"\\nüìä Aper√ßu des r√©sultats:\")\n",
    "print(df_news_unique[['title', 'sentiment', 'confidence', 'asset']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39b429",
   "metadata": {},
   "source": [
    "## 6. Statistiques et analyse des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05eca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìà STATISTIQUES GLOBALES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Statistiques de sentiment\n",
    "sentiment_counts = df_news_unique['sentiment'].value_counts()\n",
    "print(f\"\\nüé≠ Distribution des sentiments:\")\n",
    "for sentiment, count in sentiment_counts.items():\n",
    "    percentage = (count / len(df_news_unique)) * 100\n",
    "    print(f\"  {sentiment:10s}: {count:4d} news ({percentage:.1f}%)\")\n",
    "\n",
    "# Statistiques de confiance\n",
    "print(f\"\\nüéØ Confiance du mod√®le:\")\n",
    "print(f\"  Moyenne     : {df_news_unique['confidence'].mean():.2%}\")\n",
    "print(f\"  M√©diane     : {df_news_unique['confidence'].median():.2%}\")\n",
    "print(f\"  Min         : {df_news_unique['confidence'].min():.2%}\")\n",
    "print(f\"  Max         : {df_news_unique['confidence'].max():.2%}\")\n",
    "\n",
    "# Distribution par niveau de confiance\n",
    "high_conf = (df_news_unique['confidence'] > 0.8).sum()\n",
    "medium_conf = ((df_news_unique['confidence'] > 0.6) & (df_news_unique['confidence'] <= 0.8)).sum()\n",
    "low_conf = (df_news_unique['confidence'] <= 0.6).sum()\n",
    "\n",
    "print(f\"\\nüìä Distribution par confiance:\")\n",
    "print(f\"  Haute (>80%)    : {high_conf:4d} news ({(high_conf/len(df_news_unique)*100):.1f}%)\")\n",
    "print(f\"  Moyenne (60-80%): {medium_conf:4d} news ({(medium_conf/len(df_news_unique)*100):.1f}%)\")\n",
    "print(f\"  Faible (<60%)   : {low_conf:4d} news ({(low_conf/len(df_news_unique)*100):.1f}%)\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18412fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse par type d'√©v√©nement\n",
    "print(\"\\nüì∞ Sentiment par type d'√©v√©nement:\")\n",
    "event_sentiment = df_news_unique.groupby(['event_type', 'sentiment']).size().unstack(fill_value=0)\n",
    "print(event_sentiment)\n",
    "\n",
    "# Sentiment moyen par actif\n",
    "print(\"\\nüìà Top 10 actifs par nombre de news:\")\n",
    "top_assets = df_news_unique['asset'].value_counts().head(10)\n",
    "for rank, (asset, count) in enumerate(top_assets.items(), 1):\n",
    "    asset_data = df_news_unique[df_news_unique['asset'] == asset]\n",
    "    positive_pct = (asset_data['sentiment'] == 'Positive').sum() / len(asset_data) * 100\n",
    "    avg_conf = asset_data['confidence'].mean()\n",
    "    print(f\"  {rank:2d}. {asset:15s}: {count:3d} news | {positive_pct:.1f}% positive | Conf: {avg_conf:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ec788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemples de news avec sentiment positif et confiance √©lev√©e\n",
    "print(\"\\n‚úÖ Top 5 news POSITIVES (haute confiance):\")\n",
    "positive_high = df_news_unique[\n",
    "    (df_news_unique['sentiment'] == 'Positive') & \n",
    "    (df_news_unique['confidence'] > 0.8)\n",
    "].nlargest(5, 'confidence')\n",
    "\n",
    "for idx, row in positive_high.iterrows():\n",
    "    print(f\"\\n  üìå {row['title'][:70]}...\")\n",
    "    print(f\"     Asset: {row['asset']} | Confiance: {row['confidence']:.2%}\")\n",
    "\n",
    "# Exemples de news avec sentiment n√©gatif et confiance √©lev√©e\n",
    "print(\"\\n‚ùå Top 5 news N√âGATIVES (haute confiance):\")\n",
    "negative_high = df_news_unique[\n",
    "    (df_news_unique['sentiment'] == 'Negative') & \n",
    "    (df_news_unique['confidence'] > 0.8)\n",
    "].nlargest(5, 'confidence')\n",
    "\n",
    "for idx, row in negative_high.iterrows():\n",
    "    print(f\"\\n  üìå {row['title'][:70]}...\")\n",
    "    print(f\"     Asset: {row['asset']} | Confiance: {row['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0265bae0",
   "metadata": {},
   "source": [
    "## 7. R√©int√©gration avec toutes les lignes du dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merger les r√©sultats de sentiment avec le dataset complet (avec duplicatas)\n",
    "# Cela permet d'avoir le sentiment pour chaque association news-actif\n",
    "\n",
    "print(\"üîÑ Fusion des r√©sultats avec le dataset complet...\")\n",
    "\n",
    "# S√©lectionner les colonnes de sentiment\n",
    "sentiment_cols = ['url', 'sentiment', 'confidence', 'prob_negative', 'prob_positive']\n",
    "df_sentiment = df_news_unique[sentiment_cols].copy()\n",
    "\n",
    "# Fusionner avec le dataset original\n",
    "df_news_enriched = df_news.merge(df_sentiment, on='url', how='left')\n",
    "\n",
    "print(f\"‚úì Dataset enrichi: {len(df_news_enriched)} lignes\")\n",
    "print(f\"‚úì Colonnes ajout√©es: sentiment, confidence, prob_negative, prob_positive\")\n",
    "\n",
    "# V√©rifier les valeurs manquantes\n",
    "missing_sentiment = df_news_enriched['sentiment'].isna().sum()\n",
    "if missing_sentiment > 0:\n",
    "    print(f\"‚ö†Ô∏è  {missing_sentiment} lignes sans sentiment (probablement des URLs manquantes)\")\n",
    "\n",
    "# Afficher un aper√ßu\n",
    "print(\"\\nüìã Aper√ßu du dataset enrichi:\")\n",
    "df_news_enriched[['date', 'title', 'asset', 'sentiment', 'confidence', 'relevance_score']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c61a21",
   "metadata": {},
   "source": [
    "## 8. Export des r√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e299397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer un timestamp pour les fichiers de sortie\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Chemin de sortie\n",
    "output_dir = Path(\"../Pipeline_Recup_Donnees/data/raw/news\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export CSV complet (avec tous les duplicatas actif-news)\n",
    "output_csv_full = output_dir / f\"hybrid_news_sentiment_full_{timestamp}.csv\"\n",
    "df_news_enriched.to_csv(output_csv_full, index=False)\n",
    "print(f\"‚úì Dataset complet sauvegard√©: {output_csv_full}\")\n",
    "print(f\"  ({len(df_news_enriched)} lignes)\")\n",
    "\n",
    "# Export CSV news uniques uniquement\n",
    "output_csv_unique = output_dir / f\"hybrid_news_sentiment_unique_{timestamp}.csv\"\n",
    "df_news_unique.to_csv(output_csv_unique, index=False)\n",
    "print(f\"\\n‚úì News uniques sauvegard√©es: {output_csv_unique}\")\n",
    "print(f\"  ({len(df_news_unique)} news uniques)\")\n",
    "\n",
    "# Export JSON pour int√©gration API\n",
    "output_json = output_dir / f\"hybrid_news_sentiment_{timestamp}.json\"\n",
    "df_news_unique.to_json(output_json, orient='records', indent=2)\n",
    "print(f\"\\n‚úì Format JSON sauvegard√©: {output_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c99b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er un rapport r√©capitulatif\n",
    "summary_report = {\n",
    "    \"analysis_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    \"total_news\": len(df_news_unique),\n",
    "    \"total_associations\": len(df_news_enriched),\n",
    "    \"sentiment_distribution\": {\n",
    "        \"positive\": int(sentiment_counts.get('Positive', 0)),\n",
    "        \"negative\": int(sentiment_counts.get('Negative', 0)),\n",
    "        \"unknown\": int(sentiment_counts.get('Unknown', 0))\n",
    "    },\n",
    "    \"confidence_stats\": {\n",
    "        \"mean\": float(df_news_unique['confidence'].mean()),\n",
    "        \"median\": float(df_news_unique['confidence'].median()),\n",
    "        \"min\": float(df_news_unique['confidence'].min()),\n",
    "        \"max\": float(df_news_unique['confidence'].max())\n",
    "    },\n",
    "    \"top_assets\": df_news_enriched['asset'].value_counts().head(10).to_dict(),\n",
    "    \"event_types\": df_news_enriched['event_type'].value_counts().to_dict()\n",
    "}\n",
    "\n",
    "# Export du rapport en JSON\n",
    "output_summary = output_dir / f\"sentiment_analysis_summary_{timestamp}.json\"\n",
    "import json\n",
    "with open(output_summary, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary_report, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úì Rapport r√©capitulatif sauvegard√©: {output_summary}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ANALYSE DE SENTIMENT TERMIN√âE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìÅ Fichiers g√©n√©r√©s:\")\n",
    "print(f\"  1. {output_csv_full.name}\")\n",
    "print(f\"  2. {output_csv_unique.name}\")\n",
    "print(f\"  3. {output_json.name}\")\n",
    "print(f\"  4. {output_summary.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94a478",
   "metadata": {},
   "source": [
    "## 9. Visualisation des r√©sultats (Optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration du style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "\n",
    "# Cr√©er une figure avec plusieurs sous-graphiques\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Distribution des sentiments\n",
    "sentiment_counts.plot(kind='bar', ax=axes[0, 0], color=['green', 'red', 'gray'])\n",
    "axes[0, 0].set_title('Distribution des Sentiments', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Sentiment')\n",
    "axes[0, 0].set_ylabel('Nombre de News')\n",
    "axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. Distribution de la confiance\n",
    "axes[0, 1].hist(df_news_unique['confidence'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0, 1].set_title('Distribution de la Confiance', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Confiance')\n",
    "axes[0, 1].set_ylabel('Fr√©quence')\n",
    "axes[0, 1].axvline(df_news_unique['confidence'].mean(), color='red', linestyle='--', label='Moyenne')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Top 10 actifs\n",
    "top_10_assets = df_news_enriched['asset'].value_counts().head(10)\n",
    "top_10_assets.plot(kind='barh', ax=axes[1, 0], color='coral')\n",
    "axes[1, 0].set_title('Top 10 Actifs les Plus Mentionn√©s', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Nombre de News')\n",
    "axes[1, 0].set_ylabel('Actif')\n",
    "\n",
    "# 4. Sentiment par type d'√©v√©nement\n",
    "event_sentiment_pct = df_news_unique.groupby('event_type')['sentiment'].value_counts(normalize=True).unstack()\n",
    "event_sentiment_pct.plot(kind='bar', stacked=True, ax=axes[1, 1], color=['green', 'red', 'gray'])\n",
    "axes[1, 1].set_title('Sentiment par Type d\\'√âv√©nement', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Type d\\'√âv√©nement')\n",
    "axes[1, 1].set_ylabel('Proportion')\n",
    "axes[1, 1].legend(title='Sentiment')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / f\"sentiment_analysis_viz_{timestamp}.png\", dpi=300, bbox_inches='tight')\n",
    "print(f\"\\n‚úì Visualisations sauvegard√©es: sentiment_analysis_viz_{timestamp}.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
