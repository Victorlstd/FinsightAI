{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a23258",
   "metadata": {},
   "source": [
    "## 1. Installation & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "586a6e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ BibliothÃ¨ques chargÃ©es\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from newsapi import NewsApiClient\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ“ BibliothÃ¨ques chargÃ©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d268921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv(Path(\".env\"))\n",
    "newsapi = NewsApiClient(api_key=os.getenv(\"NEWSAPI_API_KEY\"))\n",
    "\n",
    "# Device (CPU ou GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1f1b9",
   "metadata": {},
   "source": [
    "## 2. Chargement de votre modÃ¨le FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7b59449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du modÃ¨le FinBERT...\n",
      "âœ“ ModÃ¨le FinBERT chargÃ© et prÃªt\n"
     ]
    }
   ],
   "source": [
    "# Charger votre modÃ¨le fine-tunÃ©\n",
    "MODEL_PATH = \"./news_finbert_sentiment_model\"\n",
    "\n",
    "print(\"Chargement du modÃ¨le FinBERT...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=2,\n",
    "    use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "print(\"âœ“ ModÃ¨le FinBERT chargÃ© et prÃªt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d0208a",
   "metadata": {},
   "source": [
    "## 3. Fonction de rÃ©cupÃ©ration de news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "890c318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_financial_news(query=\"finance OR stocks OR market\", \n",
    "                         country=None, \n",
    "                         language=\"en\",\n",
    "                         page_size=20,\n",
    "                         days_back=1):\n",
    "    \"\"\"\n",
    "    RÃ©cupÃ¨re des news financiÃ¨res via NewsAPI\n",
    "    \n",
    "    Args:\n",
    "        query: Mots-clÃ©s (ex: \"Apple OR Tesla OR Bitcoin\")\n",
    "        country: Code pays ISO (ex: \"us\", \"fr\", \"gb\") - None pour tous\n",
    "        language: Code langue (\"en\", \"fr\", etc.)\n",
    "        page_size: Nombre d'articles (max 100)\n",
    "        days_back: Nombre de jours en arriÃ¨re\n",
    "    \n",
    "    Returns:\n",
    "        Liste de dictionnaires avec les news\n",
    "    \"\"\"\n",
    "    \n",
    "    # Date de dÃ©but\n",
    "    from_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    try:\n",
    "        # Recherche d'articles\n",
    "        articles = newsapi.get_everything(\n",
    "            q=query,\n",
    "            language=language,\n",
    "            from_param=from_date,\n",
    "            sort_by='publishedAt',\n",
    "            page_size=page_size\n",
    "        )\n",
    "        \n",
    "        # Extraction des donnÃ©es pertinentes\n",
    "        news_list = []\n",
    "        for article in articles.get('articles', []):\n",
    "            news_list.append({\n",
    "                'title': article.get('title', ''),\n",
    "                'description': article.get('description', ''),\n",
    "                'content': article.get('content', ''),\n",
    "                'source': article.get('source', {}).get('name', 'Unknown'),\n",
    "                'url': article.get('url', ''),\n",
    "                'published_at': article.get('publishedAt', ''),\n",
    "                'author': article.get('author', 'Unknown')\n",
    "            })\n",
    "        \n",
    "        print(f\"âœ“ {len(news_list)} articles rÃ©cupÃ©rÃ©s\")\n",
    "        return news_list\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur API: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f89b284",
   "metadata": {},
   "source": [
    "## 4. Fonction d'analyse de sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "225ebcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text, model, tokenizer, device, max_length=512):\n",
    "    \"\"\"\n",
    "    Analyse le sentiment d'un texte avec votre modÃ¨le FinBERT\n",
    "    \n",
    "    Args:\n",
    "        text: Texte Ã  analyser\n",
    "        model: ModÃ¨le FinBERT\n",
    "        tokenizer: Tokenizer\n",
    "        device: CPU ou GPU\n",
    "        max_length: Longueur max (512 pour news)\n",
    "    \n",
    "    Returns:\n",
    "        dict avec sentiment, confiance, probabilitÃ©s\n",
    "    \"\"\"\n",
    "    \n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return {\n",
    "            'sentiment': 'Unknown',\n",
    "            'confidence': 0.0,\n",
    "            'prob_negative': 0.5,\n",
    "            'prob_positive': 0.5\n",
    "        }\n",
    "    \n",
    "    # Tokenization\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # PrÃ©diction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=1)[0]\n",
    "        \n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        confidence = probabilities[prediction].item()\n",
    "    \n",
    "    sentiment_label = \"Positive\" if prediction == 1 else \"Negative\"\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment_label,\n",
    "        'confidence': confidence,\n",
    "        'prob_negative': probabilities[0].item(),\n",
    "        'prob_positive': probabilities[1].item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e224fdb",
   "metadata": {},
   "source": [
    "## 5. Pipeline complet : Fetch + Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2282674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_news_pipeline(query=\"finance\", country=None, page_size=10):\n",
    "    \"\"\"\n",
    "    Pipeline complet : rÃ©cupÃ¨re les news et analyse le sentiment\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec news + analyse de sentiment\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ðŸ”„ DÃ‰BUT DU PIPELINE\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. RÃ©cupÃ©rer les news\n",
    "    print(f\"\\nðŸ“¡ RÃ©cupÃ©ration des news (query='{query}')...\")\n",
    "    news_list = fetch_financial_news(query=query, country=country, page_size=page_size)\n",
    "    \n",
    "    if not news_list:\n",
    "        print(\"âŒ Aucune news rÃ©cupÃ©rÃ©e\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 2. Analyser chaque news\n",
    "    print(f\"\\nðŸ¤– Analyse de sentiment en cours...\")\n",
    "    results = []\n",
    "    \n",
    "    for i, news in enumerate(news_list, 1):\n",
    "        # Combiner titre + description pour l'analyse\n",
    "        full_text = f\"{news['title']} {news['description']}\"\n",
    "        \n",
    "        # Analyser le sentiment\n",
    "        sentiment_result = analyze_sentiment(full_text, model, tokenizer, device)\n",
    "        \n",
    "        # Combiner les donnÃ©es\n",
    "        results.append({\n",
    "            'title': news['title'],\n",
    "            'source': news['source'],\n",
    "            'published_at': news['published_at'],\n",
    "            'sentiment': sentiment_result['sentiment'],\n",
    "            'confidence': sentiment_result['confidence'],\n",
    "            'prob_negative': sentiment_result['prob_negative'],\n",
    "            'prob_positive': sentiment_result['prob_positive'],\n",
    "            'url': news['url']\n",
    "        })\n",
    "        \n",
    "        # Affichage progression\n",
    "        if i % 5 == 0:\n",
    "            print(f\"   AnalysÃ© {i}/{len(news_list)} articles...\")\n",
    "    \n",
    "    # 3. CrÃ©er DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    print(f\"\\nâœ“ {len(df)} news analysÃ©es avec succÃ¨s\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de3d862",
   "metadata": {},
   "source": [
    "## ðŸ” DIAGNOSTIC : VÃ©rification des labels du modÃ¨le\n",
    "\n",
    "**ProblÃ¨me dÃ©tectÃ©** : Toutes les news sont classÃ©es \"Negative\". VÃ©rifions si les labels sont inversÃ©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69d1ce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”¬ TEST DIAGNOSTIC DES LABELS\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ Texte : Apple stock surges to record highs as earnings beat expectations. Investors cele...\n",
      "   âœ“ Sentiment attendu  : Positive\n",
      "   ðŸ¤– Sentiment prÃ©dit   : Positive\n",
      "   ðŸ“Š Prob Negative     : 21.25%\n",
      "   ðŸ“Š Prob Positive     : 78.75%\n",
      "   ðŸŽ¯ Confiance         : 78.75%\n",
      "   âœ“ Correct\n",
      "\n",
      "ðŸ“ Texte : Company files for bankruptcy amid mounting debt crisis. Shareholders face massiv...\n",
      "   âœ“ Sentiment attendu  : Negative\n",
      "   ðŸ¤– Sentiment prÃ©dit   : Negative\n",
      "   ðŸ“Š Prob Negative     : 96.03%\n",
      "   ðŸ“Š Prob Positive     : 3.97%\n",
      "   ðŸŽ¯ Confiance         : 96.03%\n",
      "   âœ“ Correct\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test 1 : News clairement positives vs nÃ©gatives\n",
    "test_cases_diagnostic = {\n",
    "    \"Positive\": \"Apple stock surges to record highs as earnings beat expectations. Investors celebrate strong revenue growth and optimistic guidance.\",\n",
    "    \"Negative\": \"Company files for bankruptcy amid mounting debt crisis. Shareholders face massive losses as stock plummets 90%.\"\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ðŸ”¬ TEST DIAGNOSTIC DES LABELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for expected_sentiment, text in test_cases_diagnostic.items():\n",
    "    result = analyze_sentiment(text, model, tokenizer, device)\n",
    "    \n",
    "    print(f\"\\nðŸ“ Texte : {text[:80]}...\")\n",
    "    print(f\"   âœ“ Sentiment attendu  : {expected_sentiment}\")\n",
    "    print(f\"   ðŸ¤– Sentiment prÃ©dit   : {result['sentiment']}\")\n",
    "    print(f\"   ðŸ“Š Prob Negative     : {result['prob_negative']:.2%}\")\n",
    "    print(f\"   ðŸ“Š Prob Positive     : {result['prob_positive']:.2%}\")\n",
    "    print(f\"   ðŸŽ¯ Confiance         : {result['confidence']:.2%}\")\n",
    "    \n",
    "    # VÃ©rification\n",
    "    if result['sentiment'] != expected_sentiment:\n",
    "        print(f\"   âš ï¸  ERREUR : Labels probablement inversÃ©s!\")\n",
    "    else:\n",
    "        print(f\"   âœ“ Correct\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacfd95",
   "metadata": {},
   "source": [
    "## ðŸ”§ SOLUTION : Fonction avec labels corrigÃ©s\n",
    "\n",
    "Si le test ci-dessus montre que les labels sont inversÃ©s, utilisez cette version corrigÃ©e :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cffd4382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ TEST AVEC LABELS CORRIGÃ‰S:\n",
      "================================================================================\n",
      "\n",
      "ðŸ“ Positive : Apple stock surges to record highs as earnings beat expectat...\n",
      "   PrÃ©dit : Negative (confiance: 78.75%)\n",
      "   âŒ\n",
      "\n",
      "ðŸ“ Negative : Company files for bankruptcy amid mounting debt crisis. Shar...\n",
      "   PrÃ©dit : Positive (confiance: 96.03%)\n",
      "   âŒ\n"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment_fixed(text, model, tokenizer, device, max_length=512):\n",
    "    \"\"\"\n",
    "    Version CORRIGÃ‰E avec labels inversÃ©s\n",
    "    0 = Positive, 1 = Negative (inversÃ© par rapport Ã  l'entraÃ®nement)\n",
    "    \"\"\"\n",
    "    \n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return {\n",
    "            'sentiment': 'Unknown',\n",
    "            'confidence': 0.0,\n",
    "            'prob_negative': 0.5,\n",
    "            'prob_positive': 0.5\n",
    "        }\n",
    "    \n",
    "    # Tokenization\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # PrÃ©diction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=1)[0]\n",
    "        \n",
    "        prediction = torch.argmax(logits, dim=1).item()\n",
    "        confidence = probabilities[prediction].item()\n",
    "    \n",
    "    # ðŸ”§ CORRECTION : Inverser les labels\n",
    "    # Le modÃ¨le a appris : 0=Negative, 1=Positive\n",
    "    # Mais on veut      : 0=Positive, 1=Negative (convention standard)\n",
    "    sentiment_label = \"Negative\" if prediction == 1 else \"Positive\"\n",
    "    \n",
    "    return {\n",
    "        'sentiment': sentiment_label,\n",
    "        'confidence': confidence,\n",
    "        'prob_positive': probabilities[0].item(),  # InversÃ©\n",
    "        'prob_negative': probabilities[1].item()   # InversÃ©\n",
    "    }\n",
    "\n",
    "# Test avec la version corrigÃ©e\n",
    "print(\"ðŸ”§ TEST AVEC LABELS CORRIGÃ‰S:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for expected_sentiment, text in test_cases_diagnostic.items():\n",
    "    result = analyze_sentiment_fixed(text, model, tokenizer, device)\n",
    "    \n",
    "    print(f\"\\nðŸ“ {expected_sentiment} : {text[:60]}...\")\n",
    "    print(f\"   PrÃ©dit : {result['sentiment']} (confiance: {result['confidence']:.2%})\")\n",
    "    print(f\"   âœ“\" if result['sentiment'] == expected_sentiment else \"   âŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e683b1a5",
   "metadata": {},
   "source": [
    "## 6. Exemples d'utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9faf79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”„ DÃ‰BUT DU PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“¡ RÃ©cupÃ©ration des news (query='stocks OR market OR trading')...\n",
      "âœ“ 10 articles rÃ©cupÃ©rÃ©s\n",
      "\n",
      "ðŸ¤– Analyse de sentiment en cours...\n",
      "   AnalysÃ© 5/10 articles...\n",
      "   AnalysÃ© 10/10 articles...\n",
      "\n",
      "âœ“ 10 news analysÃ©es avec succÃ¨s\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š RÃ‰SULTATS\n",
      "                                               title sentiment  confidence\n",
      "0  NorthStar Achieves Commercial-Scale Ac-225 Pro...  Positive    0.834642\n",
      "1  Trump wonâ€™t rule out military force to acquire...  Negative    0.941200\n",
      "2  Letenda is building new 30-ft electric midibus...  Negative    0.577747\n",
      "3  Joby Aviation to acquire manufacturing facilit...  Negative    0.597531\n",
      "4  United Airlines price target raised by $13 at ...  Positive    0.576018\n",
      "5  JetBlue price target raised by $1 at TD Cowen,...  Positive    0.547066\n",
      "6  Delta Air Lines price target raised by $5 at T...  Positive    0.650701\n",
      "7  Fullerton Health Deepens Specialty Care Capabi...  Positive    0.810705\n",
      "8  CoinDesk 20 Performance Update: Uniswap (UNI) ...  Negative    0.937489\n",
      "9  American Airlines price target raised by $3 at...  Positive    0.615079\n"
     ]
    }
   ],
   "source": [
    "# Exemple 1 : News gÃ©nÃ©rales sur la finance\n",
    "df_finance = analyze_news_pipeline(\n",
    "    query=\"stocks OR market OR trading\",\n",
    "    page_size=10\n",
    ")\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(\"\\nðŸ“Š RÃ‰SULTATS\")\n",
    "print(df_finance[['title', 'sentiment', 'confidence']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8574b096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”„ DÃ‰BUT DU PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“¡ RÃ©cupÃ©ration des news (query='Apple OR Tesla OR Microsoft OR Google')...\n",
      "âœ“ 15 articles rÃ©cupÃ©rÃ©s\n",
      "\n",
      "ðŸ¤– Analyse de sentiment en cours...\n",
      "   AnalysÃ© 5/15 articles...\n",
      "   AnalysÃ© 10/15 articles...\n",
      "   AnalysÃ© 15/15 articles...\n",
      "\n",
      "âœ“ 15 news analysÃ©es avec succÃ¨s\n",
      "================================================================================\n",
      "\n",
      "ðŸŽ¯ News avec confiance > 80% : 4 articles\n",
      "                                                title sentiment  confidence\n",
      "0   Lutron's Smart Blinds Know Exactly When the Su...  Positive    0.838816\n",
      "1   Lutron's Smart Blinds Know Exactly When the Su...  Positive    0.838816\n",
      "12  Mamdaniâ€™s woke, white tenant advocate Cea Weav...  Negative    0.944135\n",
      "13  Iâ€™m a trained TV calibrator, and here are the ...  Positive    0.843425\n"
     ]
    }
   ],
   "source": [
    "# Exemple 2 : News sur des entreprises spÃ©cifiques\n",
    "df_tech = analyze_news_pipeline(\n",
    "    query=\"Apple OR Tesla OR Microsoft OR Google\",\n",
    "    page_size=15\n",
    ")\n",
    "\n",
    "# Filtrer par confiance Ã©levÃ©e (> 80%)\n",
    "df_high_confidence = df_tech[df_tech['confidence'] > 0.8]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ News avec confiance > 80% : {len(df_high_confidence)} articles\")\n",
    "print(df_high_confidence[['title', 'sentiment', 'confidence']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44383532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ STATISTIQUES\n",
      "Sentiment positif : 9 articles\n",
      "Sentiment nÃ©gatif : 6 articles\n",
      "\n",
      "Confiance moyenne : 69.01%\n"
     ]
    }
   ],
   "source": [
    "# Exemple 3 : Analyse par sentiment\n",
    "print(\"\\nðŸ“ˆ STATISTIQUES\")\n",
    "print(f\"Sentiment positif : {(df_tech['sentiment'] == 'Positive').sum()} articles\")\n",
    "print(f\"Sentiment nÃ©gatif : {(df_tech['sentiment'] == 'Negative').sum()} articles\")\n",
    "print(f\"\\nConfiance moyenne : {df_tech['confidence'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a564e",
   "metadata": {},
   "source": [
    "## 7. Export des rÃ©sultats (pour intÃ©gration Ã©quipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9b564dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ RÃ©sultats sauvegardÃ©s dans : sentiment_analysis_20260108_151914.csv\n",
      "âœ“ RÃ©sultats JSON dans : sentiment_analysis_20260108_151914.json\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder en CSV\n",
    "output_file = f\"sentiment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df_tech.to_csv(output_file, index=False)\n",
    "print(f\"âœ“ RÃ©sultats sauvegardÃ©s dans : {output_file}\")\n",
    "\n",
    "# Ou en JSON pour API\n",
    "output_json = output_file.replace('.csv', '.json')\n",
    "df_tech.to_json(output_json, orient='records', indent=2)\n",
    "print(f\"âœ“ RÃ©sultats JSON dans : {output_json}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863d90f",
   "metadata": {},
   "source": [
    "## 8. Fonction API-ready pour votre Ã©quipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d05d6e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”„ DÃ‰BUT DU PIPELINE\n",
      "================================================================================\n",
      "\n",
      "ðŸ“¡ RÃ©cupÃ©ration des news (query='cryptocurrency')...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ 5 articles rÃ©cupÃ©rÃ©s\n",
      "\n",
      "ðŸ¤– Analyse de sentiment en cours...\n",
      "   AnalysÃ© 5/5 articles...\n",
      "\n",
      "âœ“ 5 news analysÃ©es avec succÃ¨s\n",
      "================================================================================\n",
      "\n",
      "Status: success\n",
      "Total: 5 articles\n",
      "Positif: 2, NÃ©gatif: 3\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment_analysis(query, max_results=20):\n",
    "    \"\"\"\n",
    "    Fonction simple pour l'Ã©quipe backend/frontend\n",
    "    \n",
    "    Args:\n",
    "        query: RequÃªte de recherche\n",
    "        max_results: Nombre max de rÃ©sultats\n",
    "    \n",
    "    Returns:\n",
    "        dict formatÃ© pour API\n",
    "    \"\"\"\n",
    "    df = analyze_news_pipeline(query=query, page_size=max_results)\n",
    "    \n",
    "    if df.empty:\n",
    "        return {\"status\": \"error\", \"message\": \"No news found\", \"data\": []}\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"query\": query,\n",
    "        \"total_articles\": len(df),\n",
    "        \"positive_count\": (df['sentiment'] == 'Positive').sum(),\n",
    "        \"negative_count\": (df['sentiment'] == 'Negative').sum(),\n",
    "        \"average_confidence\": float(df['confidence'].mean()),\n",
    "        \"articles\": df.to_dict('records')\n",
    "    }\n",
    "\n",
    "# Test\n",
    "result = get_sentiment_analysis(\"cryptocurrency\", max_results=5)\n",
    "print(f\"\\nStatus: {result['status']}\")\n",
    "print(f\"Total: {result['total_articles']} articles\")\n",
    "print(f\"Positif: {result['positive_count']}, NÃ©gatif: {result['negative_count']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
